{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2281e88e",
   "metadata": {},
   "source": [
    "# # Web-Search SDK Walk-Through\n",
    "# Simple, end-to-end demo showing installation, scraping helpers,\n",
    "# debugging flags, and output utilities.\n",
    "# \n",
    "# Repo: <https://github.com/.../web-search-sdk>\n",
    "# Docs: README.md & Progress_Report_v0.2.0.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c62554",
   "metadata": {},
   "source": [
    "# ## 0  Bootstrap – clone repo if needed\n",
    "# This notebook can run standalone (e.g., Colab). It clones the\n",
    "# web-search-sdk repo into `./web-search-sdk` when it does not already\n",
    "# exist and defines REPO_ROOT so subsequent imports work regardless of\n",
    "# where the notebook is opened.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, pathlib, importlib\n",
    "\n",
    "GIT_PRESENT = pathlib.Path(\".git\").exists()\n",
    "if GIT_PRESENT:\n",
    "    # Notebook already running inside a clone\n",
    "    REPO_ROOT = str(pathlib.Path.cwd())\n",
    "    print(\"Running inside repo – no clone needed\")\n",
    "else:\n",
    "    REPO_URL = os.getenv(\"REPO_URL\", \"https://github.com/Gregory-307/web-search-sdk.git\")\n",
    "    WORKDIR = pathlib.Path(\"web-search-sdk\").resolve()\n",
    "    if not WORKDIR.exists():\n",
    "        print(\"Cloning repo …\", REPO_URL)\n",
    "        subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(WORKDIR)])\n",
    "    REPO_ROOT = str(WORKDIR)\n",
    "\n",
    "# Expose repo root to Python path for imports\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Install package (editable) and Playwright browsers – NB-02 & NB-03\n",
    "# ------------------------------------------------------------------\n",
    "import subprocess, sys\n",
    "\n",
    "def _run(cmd):\n",
    "    print(\"$\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# Upgrade pip quietly\n",
    "_run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", \"pip\"])\n",
    "\n",
    "# Install repo in editable mode with extras\n",
    "_run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", f\"{REPO_ROOT}[browser,test]\"])\n",
    "\n",
    "# Install Playwright browsers once\n",
    "try:\n",
    "    import playwright  # type: ignore\n",
    "    _run([sys.executable, \"-m\", \"playwright\", \"install\", \"--with-deps\"])\n",
    "except Exception as exc:  # noqa: BLE001\n",
    "    print(\"Playwright install skipped/failed:\", exc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca0017",
   "metadata": {},
   "source": [
    "# ### Offline Mode (info)\n",
    "# This section previously documented an environment stub. Network calls now run\n",
    "# directly, so no setup is required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline mode guard removed; network calls will execute normally\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b983c4",
   "metadata": {},
   "source": [
    "# ## 2  Smoke Test\n",
    "# Quick import & built-in smoke test to verify the setup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e08fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, runpy, asyncio, sys\n",
    "print(\"web_search_sdk version:\", importlib.import_module(\"web_search_sdk\").__version__)\n",
    "runpy.run_path(\"smoke_test.py\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92b351",
   "metadata": {},
   "source": [
    "# ## 3  ScraperContext Basics\n",
    "# Demonstrate the most common context configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.base import ScraperContext\n",
    "ctx_http  = ScraperContext()\n",
    "ctx_selen = ScraperContext(use_browser=True, browser_type=\"selenium\", debug=True)\n",
    "ctx_play  = ScraperContext(use_browser=True, browser_type=\"playwright_stealth\")\n",
    "ctx_http, ctx_selen, ctx_play\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a7137",
   "metadata": {},
   "source": [
    "# ## 4  DuckDuckGo Top-Words Demo (Primary Engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.duckduckgo_web import duckduckgo_top_words\n",
    "await duckduckgo_top_words(\"bitcoin swing\", ctx_http, top_n=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed970f",
   "metadata": {},
   "source": [
    "# ## 4.1  Wikipedia Top-Words Demo\n",
    "# Wikipedia is a low-latency, high-coverage source that rarely blocks\n",
    "# automated requests.  The helper fetches the page, strips boiler-plate\n",
    "# and returns the top-N tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.wikipedia import wikipedia_top_words\n",
    "await wikipedia_top_words(\"bitcoin\", ctx_http, top_n=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f008af",
   "metadata": {},
   "source": [
    "# ## 4.2  RelatedWords Synonym Demo\n",
    "# Uses the RelatedWords.org API (with HTML fallback) to pull semantically\n",
    "# similar terms.  Useful for expanding keyword seed lists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.related import related_words\n",
    "await related_words(\"bitcoin\", ctx_http)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0f8b3",
   "metadata": {},
   "source": [
    "# ## 4.3  Google News RSS Demo\n",
    "# Headlines often surface fresh jargon sooner than static pages.  The helper\n",
    "# parses the Google News RSS feed and extracts the most frequent tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.news import google_news_top_words\n",
    "await google_news_top_words(\"bitcoin\", ctx_http, top_n=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23101a2",
   "metadata": {},
   "source": [
    "# ## 4.4  Google Trends Interest Over Time\n",
    "# Historical interest curve via the PyTrends wrapper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.trends import interest_over_time\n",
    "import pandas as pd\n",
    "df = await interest_over_time(\"bitcoin\")\n",
    "display(df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2f8f1",
   "metadata": {},
   "source": [
    "# ## 4.5  Stock Price Fetch\n",
    "# Fetch OHLCV data via yfinance for context charts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66dd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.stock import fetch_stock_data\n",
    "df_price = await fetch_stock_data(\"BTC-USD\", ctx_http)\n",
    "display(df_price.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22d526",
   "metadata": {},
   "source": [
    "# ## 4.6  Parallel Scraping with `gather_scrapers`\n",
    "# Fetch top DuckDuckGo tokens for multiple terms concurrently in a single call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.base import gather_scrapers\n",
    "from web_search_sdk.scrapers.duckduckgo_web import _fetch_html as _ddg_fetch, _parse_html as _ddg_parse\n",
    "\n",
    "terms = [\"bitcoin\", \"ethereum\", \"dogecoin\"]\n",
    "\n",
    "async def _parse_wrapper(html: str, term: str, ctx):\n",
    "    return _ddg_parse(html, top_n=5)\n",
    "\n",
    "tokens_list = await gather_scrapers(\n",
    "    terms,\n",
    "    fetch=_ddg_fetch,\n",
    "    parse=_parse_wrapper,\n",
    "    ctx=ctx_http,\n",
    ")\n",
    "result_map = dict(zip(terms, tokens_list))\n",
    "result_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadf1b0",
   "metadata": {},
   "source": [
    "# ## 5  Google SERP Fallback\n",
    "# DuckDuckGo is reliable enough for most use-cases; a Google fallback adds\n",
    "# extra latency and may hit CAPTCHA but is now always executed for demo purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.google_web import google_web_top_words\n",
    "tokens = await google_web_top_words(\"bitcoin swing\", ctx_play, top_n=20)\n",
    "print(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45487869",
   "metadata": {},
   "source": [
    "# ## 6  Combined Helper: `search_and_parse`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e7823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.search import search_and_parse\n",
    "res = await search_and_parse(\"btc rally\", ctx_play, top_n=10)\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3b711",
   "metadata": {},
   "source": [
    "# ## 7  Paywall Article Retrieval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6190cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.paywall import fetch_bloomberg\n",
    "article_html = await fetch_bloomberg(\"https://www.bloomberg.com/...\", ctx_play)\n",
    "print(article_html[:800])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b21098",
   "metadata": {},
   "source": [
    "# ## 8  Output Utilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e38747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.utils.output import to_json\n",
    "import pathlib, json, os\n",
    "pathlib.Path(\"out\").mkdir(exist_ok=True)\n",
    "json_path = \"out/tokens.json\"\n",
    "to_json(res[\"tokens\"], json_path, append=True)\n",
    "print(json_path, \"->\", os.path.getsize(json_path), \"bytes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4df03",
   "metadata": {},
   "source": [
    "# ### CSV helper\n",
    "# The `to_csv` utility creates or appends rows to a CSV file – handy for quick\n",
    "# dumps that Excel/Sheets can open.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.utils.output import to_csv\n",
    "def _first_five_tokens(tok):\n",
    "    \"\"\"Return up to first five token strings regardless of collection type.\"\"\"\n",
    "    if isinstance(tok, dict):\n",
    "        seq = list(tok.keys())\n",
    "    elif isinstance(tok, (list, tuple, set)):\n",
    "        seq = list(tok)\n",
    "    else:\n",
    "        seq = [str(tok)]\n",
    "    return \",\".join(map(str, seq[:5]))\n",
    "\n",
    "rows = [{\"term\": term, \"top5\": _first_five_tokens(tokens)} for term, tokens in result_map.items()]\n",
    "csv_path = \"out/tokens.csv\"\n",
    "to_csv(rows, csv_path, append=False)  # overwrite for demo\n",
    "print(csv_path, \"->\", os.path.getsize(csv_path), \"bytes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append another record to tokens.json using to_json(..., append=True)\n",
    "more_tokens = {\"source\": \"google_news\", \"tokens\": await google_news_top_words(\"ethereum\", ctx_http, top_n=10)}\n",
    "to_json(more_tokens, json_path, append=True)\n",
    "print(\"Appended second record to\", json_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a79f8",
   "metadata": {},
   "source": [
    "# ## 4.7  Rate-Limit Decorator Example\n",
    "# The `utils.rate_limit.rate_limiter` decorator provides an async token-bucket\n",
    "# to cap outbound request rates.  Below we allow just **2 calls per second**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from web_search_sdk.utils.rate_limit import rate_limited\n",
    "\n",
    "@rate_limited(calls=2, period=1.0)\n",
    "async def _echo(i: int):\n",
    "    print(\"tick\", i)\n",
    "\n",
    "await asyncio.gather(*[_echo(i) for i in range(5)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e327b",
   "metadata": {},
   "source": [
    "# ## 4.8  Text Utility Helpers\n",
    "# A grab-bag of small string helpers used across scrapers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f8e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.utils.text import tokenise, remove_stopwords, most_common\n",
    "\n",
    "raw = \"Bitcoin's all-time high price sparks FOMO!\"\n",
    "tokens = tokenise(raw)\n",
    "print(\"tokens:\", tokens)\n",
    "print(\"no stopwords:\", remove_stopwords(tokens))\n",
    "print(\"top words:\", most_common(tokens, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3936939",
   "metadata": {},
   "source": [
    "# ## 4.9  Custom User-Agent Rotation\n",
    "# `ScraperContext`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}