{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5e7d39",
   "metadata": {},
   "source": [
    "# # Web-Search SDK – End-to-End Demo (V2)\n",
    "# \n",
    "# This notebook shows **how to install, configure and use** the SDK to pull\n",
    "# publicly-available web signals – from simple keyword extraction to\n",
    "# paywall handling and Twitter scraping – in **under 3 minutes**.\n",
    "# \n",
    "# <https://github.com/Gregory-307/web-search-sdk>\n",
    "# \n",
    "# ---\n",
    "# **Tip** Set `OFFLINE_MODE=1` to run everything against fixture HTML – great\n",
    "# for CI or airplane mode!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d5db5",
   "metadata": {},
   "source": [
    "# ## 1  Environment Setup  \n",
    "# This cell **bootstraps a completely fresh Colab**:\n",
    "# 1. Installs the Web-Search SDK in *editable* mode (if missing).\n",
    "# 2. Installs the Playwright Python package (if missing).\n",
    "# 3. Downloads headless browser binaries (idempotent).\n",
    "#\n",
    "# Feel free to run it multiple times – each step is safe and will be skipped\n",
    "# when already satisfied.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, pathlib, os, sys\n",
    "\n",
    "# Clone repo when notebook is opened outside the repository tree (e.g. Colab)\n",
    "REPO_URL = \"https://github.com/Gregory-307/web-search-sdk.git\"\n",
    "REPO_DIR = pathlib.Path(\"web-search-sdk\")\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    print(\"Cloning repo …\")\n",
    "    subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(REPO_DIR)])\n",
    "\n",
    "ROOT = REPO_DIR.resolve()\n",
    "\n",
    "# Install SDK (editable) + Playwright package & browsers – always runs, safe and idempotent\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", f\"{ROOT}[browser]\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"playwright\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"playwright\", \"install\", \"--with-deps\"], stdout=subprocess.DEVNULL)\n",
    "\n",
    "# Make repo importable\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "print(\"✅ Environment ready\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7788e54",
   "metadata": {},
   "source": [
    "# ## 2  Quick Smoke Test\n",
    "# Verifies that the freshly-installed package is importable and that the\n",
    "# built-in `smoke_test.py` script runs without network access.  \n",
    "# **Expected output**: version string + a list of top-tokens for the term you\n",
    "# pass on the CLI (defaults inside the script).  This takes <2 s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import runpy, importlib.metadata as md, pathlib\n",
    "print(\"web_search_sdk version:\", md.version(\"web-search-sdk\"))\n",
    "runpy.run_path(str((pathlib.Path.cwd() / \"web-search-sdk\" / \"smoke_test.py\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2a821",
   "metadata": {},
   "source": [
    "# ## 3  ScraperContext Cheatsheet\n",
    "# `ScraperContext` is the _single_ configuration object shared by every helper\n",
    "# in the SDK.  It controls:\n",
    "# • HTTP headers, timeouts & retries  \n",
    "# • Proxy / custom User-Agent pools  \n",
    "# • Whether to launch a headless browser fallback (Selenium / Playwright)  \n",
    "# • Verbose logging for debugging\n",
    "#\n",
    "# The cell below instantiates three ready-made contexts to reuse in later\n",
    "# examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65700595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.base import ScraperContext\n",
    "ctx_http  = ScraperContext()\n",
    "ctx_selen = ScraperContext(use_browser=True, browser_type=\"selenium\", debug=False)\n",
    "ctx_play  = ScraperContext(use_browser=True, browser_type=\"playwright_stealth\")\n",
    "ctx_http, ctx_selen, ctx_play\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be53bed",
   "metadata": {},
   "source": [
    "# ## Part A – Scraping Helpers\n",
    "# ### A1 Keyword Extractors – DuckDuckGo SERP\n",
    "# Primary engine: zero CAPTCHA risk, lightweight HTML.  Returns top-N tokens\n",
    "# from the SERP snippets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45921ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.duckduckgo_web import duckduckgo_top_words\n",
    "print(await duckduckgo_top_words(\"bitcoin swing\", ctx_http, top_n=15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249b4cd",
   "metadata": {},
   "source": [
    "# ### A2 Keyword Extractors – Wikipedia Page\n",
    "# Low-latency and highly reliable.  Good sanity-check source for any term.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c44655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.wikipedia import wikipedia_top_words\n",
    "print(await wikipedia_top_words(\"bitcoin\", ctx_http, top_n=15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dc6703",
   "metadata": {},
   "source": [
    "# ### A3 Semantic Expansion – RelatedWords\n",
    "# Expands the seed term via semantic similarity API; useful for idea\n",
    "# generation or keyword expansion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.related import related_words\n",
    "_syn = await related_words(\"bitcoin\", ctx_http)\n",
    "print(_syn[:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47bfc5",
   "metadata": {},
   "source": [
    "# ### A4 Keyword Extractors – Google News RSS\n",
    "# Headlines surface fresh jargon earlier than static pages – this parser\n",
    "# extracts frequent tokens from the Google News RSS feed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.news import google_news_top_words\n",
    "print(await google_news_top_words(\"bitcoin\", ctx_http, top_n=15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1638853",
   "metadata": {},
   "source": [
    "# ### A4 Google SERP Fallback *(optional)*\n",
    "# Heavy and may hit CAPTCHA – **runs by default**. Set `DISABLE_GOOGLE=1` to skip in CI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Skip only when explicitly disabled\n",
    "if os.getenv(\"DISABLE_GOOGLE\") == \"1\":\n",
    "    print(\"[skipped] DISABLE_GOOGLE env var set\")\n",
    "else:\n",
    "    from web_search_sdk.scrapers.google_web import google_web_top_words\n",
    "    print(await google_web_top_words(\"bitcoin swing\", ctx_play, top_n=15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb23a1",
   "metadata": {},
   "source": [
    "# ### A5 Browser Fetch Example – CNBC (no paywall)\n",
    "# Demonstrates Playwright-powered rendering for dynamic pages. Fetches the\n",
    "# article HTML from CNBC (public, no paywall) and prints the first 400 chars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.browser import fetch_html as _browser_fetch_html\n",
    "\n",
    "def _cnbc_url(term:str)->str:\n",
    "    return \"https://www.cnbc.com/2023/12/01/bitcoin-rallies-above-40000.html\"\n",
    "\n",
    "html = await _browser_fetch_html(\"bitcoin\", _cnbc_url, ctx_play)\n",
    "print(html[:400], \"…\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d1f6e",
   "metadata": {},
   "source": [
    "# ## Part B – Toolkit Helpers\n",
    "# ### B1 Output Utilities (JSON/CSV)\n",
    "# Lightweight helpers that write structured results to JSON/CSV.  Both create\n",
    "# parent folders automatically and support **append** mode for easy logging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76849cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.utils.output import to_json, to_csv\n",
    "import json, pathlib\n",
    "pathlib.Path(\"out\").mkdir(exist_ok=True)\n",
    "\n",
    "json_path = \"out/demo_tokens.json\"\n",
    "to_json([\"btc\", \"eth\", \"doge\"], json_path, append=False)\n",
    "print(\"Wrote\", json_path, \"bytes:\", pathlib.Path(json_path).stat().st_size)\n",
    "\n",
    "csv_path = \"out/demo_tokens.csv\"\n",
    "to_csv([{\"term\": \"btc\", \"hits\": 120}], csv_path, append=False)\n",
    "print(\"Wrote\", csv_path, \"bytes:\", pathlib.Path(csv_path).stat().st_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8859c",
   "metadata": {},
   "source": [
    "# ### B2 Text Helpers\n",
    "# Tokenisation + stop-word removal + frequency counter in one line each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.utils.text import tokenise, remove_stopwords, most_common\n",
    "raw = \"Bitcoin's all-time high price sparks FOMO!\"\n",
    "print(\"tokens:\", tokenise(raw))\n",
    "print(\"no stopwords:\", remove_stopwords(tokenise(raw)))\n",
    "print(\"top:\", most_common(tokenise(raw), 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c7169",
   "metadata": {},
   "source": [
    "# ### B3 Rate-Limit Decorator\n",
    "# Async token-bucket decorator – guarantees you never exceed X calls / period.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from web_search_sdk.utils.rate_limit import rate_limited\n",
    "\n",
    "@rate_limited(calls=2, period=1.0)\n",
    "async def _ping(i: int):\n",
    "    print(\"tick\", i)\n",
    "\n",
    "await asyncio.gather(*[_ping(i) for i in range(5)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5bb7c",
   "metadata": {},
   "source": [
    "# ### B4 Parallel Scraping Helper\n",
    "# Uses `gather_scrapers` to fan-out N async tasks with a bounded semaphore.\n",
    "# Total runtime ≈ max(single request latency) instead of sum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7614f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_search_sdk.scrapers.base import gather_scrapers\n",
    "from web_search_sdk.scrapers.duckduckgo_web import _fetch_html as _ddg_fetch, _parse_html as _ddg_parse\n",
    "\n",
    "terms = [\"bitcoin\", \"ethereum\", \"solana\"]\n",
    "async def _parse_wrapper(html: str, term: str, ctx):\n",
    "    return _ddg_parse(html, top_n=5)\n",
    "\n",
    "print(await gather_scrapers(terms, fetch=_ddg_fetch, parse=_parse_wrapper, ctx=ctx_http))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1815615",
   "metadata": {},
   "source": [
    "# ## 12  Closing Notes\n",
    "# • Roadmap → `Progress_Report_v0.2.0.md`  \n",
    "# • Found it useful? **Star** the repo ⭐ & consider contributing – guidelines\n",
    "#   in `CONTRIBUTING.md`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}